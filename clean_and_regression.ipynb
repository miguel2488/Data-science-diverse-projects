{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def filter_nyc(filename = 'nyc.csv'):\n",
    "    #read_csv\n",
    "    df = pd.read_csv(filename,header=0)\n",
    "    #drop unnamed column\n",
    "    df.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "    #convert to date\n",
    "    df['Created Date'] = pd.to_datetime(df['Created Date'], infer_datetime_format = True)\n",
    "    df['Closed Date'] = pd.to_datetime(df['Closed Date'], infer_datetime_format = True)\n",
    "    #extract month\n",
    "    df['month'] = df['Created Date'].apply(lambda x: x.month)\n",
    "    #extract hour\n",
    "    df['hour'] = df['Created Date'].apply(lambda x: x.hour)\n",
    "    #extract day\n",
    "    df['weekday'] = df['Created Date'].apply(lambda x: x.dayofweek)\n",
    "    #map agency num\n",
    "    agency_num = {}\n",
    "    for num, agency in enumerate((df['Agency'].unique())): \n",
    "        agency_num[agency] = num   \n",
    "    df['agency_num'] = df['Agency'].apply(lambda x: agency_num[x])\n",
    "    #map borough num\n",
    "    d = {'MANHATTAN':1, 'BROOKLYN':2, 'QUEENS' : 3, 'STATEN ISLAND' : 4, 'BRONX' : 5}\n",
    "    pat = '(' + '|'.join(d.keys()) + ')'\n",
    "    df['borough_num'] = df['Borough'].str.extract(pat, expand=False).map(d).fillna(0, downcast='int')\n",
    "    #drop borough == 0\n",
    "    df = df[df.borough_num != 0]\n",
    "    #create bucket column\n",
    "    df['processing_time_bucket'] = df.processing_time.map( lambda x: 1 if x >= 1 else 0)\n",
    "    #subset\n",
    "    df = df[['hour','month', 'weekday', 'agency_num', 'borough_num', 'processing_time_bucket']]\n",
    "    df.to_csv('filtered.csv',index=False)\n",
    "    \n",
    "def build_and_predict():\n",
    "    data = pd.read_csv('filtered.csv')\n",
    "    test = pd.read_csv('topredict.csv')\n",
    "    #model\n",
    "    model = LogisticRegression()\n",
    "    #split\n",
    "    '''from sklearn.model_selection import train_test_split\n",
    "    #y = data['processing_time_bucket']\n",
    "    #data.drop(columns = ['processing_time_bucket'], inplace = True)\n",
    "    train, test = train_test_split(data, test_size = 0.3)\n",
    "    x_train = train.iloc[0:,0:6]\n",
    "    y_train = train.iloc[0:,5:6]\n",
    "    x_test = test.iloc[0:,0:6]\n",
    "    y_test = test['processing_time_bucket']\n",
    "    y_train'''\n",
    "    y_train = data['processing_time_bucket']\n",
    "    x_train = data.iloc[0:, 0:5]\n",
    "    #fit\n",
    "    model.fit(x_train, y_train)\n",
    "    #predict\n",
    "    predictions = model.predict(test)\n",
    "    predictions = pd.DataFrame(predictions, columns = ['prediction'])\n",
    "    predictions.to_csv('predictions.csv', index_label = 'index')\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
